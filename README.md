# Detection of Message Authenticity: A Modern Approach
# Introduction
As SMS spammers are getting smarter about the ways they create spam messages, it is essential for our classification algorithms to work with higher accuracy since it has become difficult for people to self-identify frauds. The aim of our exploration is to challenge Support Vector Machines that are said to be highly accurate at detecting spam messages. To carry out our analysis we have compared Bidirectional Encoder Representations from Transformers (BERT), Support Vector Machines (SVM), Sequential Neural Networks, and Long Short-Term Memory (LSTM) models which are well-known language models that are highly efficient in classifying text. Our approach was to compare each model under four different scenarios where the sampling method and root word generation were changed. We pursued this approach to see if changing the methodology for processing corpus has an effect on these models or not. The accuracy of each model under these four scenarios was compared since we are interested to see how well the model has been able to classify the spam messages from the ham messages. The corpus that was used for this is taken from the UCI Repository which is under the name of ‘SMS Spam collection Data Set’ and consists of 5574 instances where 13.4% of messages were labeled as spam and the other 86.6% of messages were labeled as ham. Since there was an imbalance in the target variable of our corpus, we decided to undersample our ham messages, to see if the imbalance had
an effect on our model performances. Moreover, we have compared both stemming and lemmatization for the pre-processing of our corpus since root word generation can also have an effect on how the language models behave.
# Background
The paper titled “Contributions to the study of SMS spam filtering: new collection and results” which was published in 2011, focuses on the aspect of Support Vector Machines which acts as the best classifier outperforming the rest. The classifiers that were compared in this paper were Support Vector Machine and various Naive Bayes classifiers such as basic, multivariate gaussian, multinomial boolean, boolean, boosted, and flexible Bayes. Our goal was to test newer models that are more robust such as BERT, LSTM, and Sequential Neural Networks, in order to challenge the Support Vector Machine under different scenarios.
# Approach
As per the paper that was published in 2011, used techniques such as SVM, Naive Bayes, etc, we felt that a lot of new NLP techniques have been in use since then such as BERT, LSTM, Neural Networks, TFIDF, etc have been in use and is preferred over a lot of the older techniques.
# Data Preprocessing and Cleaning
To check for the distribution of our spam and ham messages we counted and found that 86.6% of messages were ham and 13.4% of messages were spam. From this analysis, we decided to use sampling techniques and compare our models to see if sampling has an effect on model performance. We then dropped the duplicates that were present in our corpus. Along with this, we also visualized the 4 different parameters: The number of characters in a
message, the Number of words in a message, the Number of sentences in a message, and the length of the message. This showed us clearly that messages that were spam had a larger text length as compared to spam which was one of the conclusions that we drew from this analysis.
On further exploratory analysis, we found that the most common words that were used in spam messages were ‘call’, ‘free’, ‘txt’, etc. The corpus was then made free of stop words, punctuations, URLs, numbers, etc, and then created into four categories: Sampled Lemmatized, Unsampled Lemmatized, Sampled & Stemmed, and Unsampled & Stemmed. We have tokenized the text streams into tokens as well. The classes which were ham and spam were target encoded in order to convert the text into ‘0’ and ‘1’ for the models to comprehend. We also used word embedding techniques such as CountVectorizer and TF-IDF Vectorizer which essentially helps us convert our corpus to vectors for our models to interpret.
# Model Implementation
For all our models we have divided our corpus into testing and training sets where training consists of 75% of the corpus and testing consists of 25% of the corpus. The models that we have used are Bidirectional Encoder Representations from Transformers (BERT), Support Vector Machines (SVM), Sequential Neural Networks, and Long Short-Term Memory (LSTM).
